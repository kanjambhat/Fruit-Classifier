{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation,Dense,Dropout\n",
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(filters=16,kernel_size=2,input_shape=(64,64,3),padding='same',activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(filters=32,kernel_size=2,padding='same',activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(filters=64,kernel_size=2,padding='same',activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(filters=128,kernel_size=2,padding='same',activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=150,activation='relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(units=131,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 64, 64, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 150)               307350    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 131)               19781     \n",
      "=================================================================\n",
      "Total params: 370,571\n",
      "Trainable params: 370,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67692 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(r'C:\\fruit_classification_project\\fruits-360\\Training',\n",
    "                                               target_size=(64,64),\n",
    "                                               batch_size=12,\n",
    "                                               class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22688 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set=test_datagen.flow_from_directory(r'C:\\fruit_classification_project\\fruits-360\\Test',\n",
    "                                               target_size=(64,64),\n",
    "                                               batch_size=12,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanjam Bhat Lidhoo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "C:\\Users\\Kanjam Bhat Lidhoo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=5641, epochs=20, validation_steps=300)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5641/5641 [==============================] - 1566s 278ms/step - loss: 1.6464 - accuracy: 0.5344 - val_loss: 0.1234 - val_accuracy: 0.8608\n",
      "Epoch 2/20\n",
      "5641/5641 [==============================] - 447s 79ms/step - loss: 0.4888 - accuracy: 0.8312 - val_loss: 0.4361 - val_accuracy: 0.9261\n",
      "Epoch 3/20\n",
      "5641/5641 [==============================] - 443s 79ms/step - loss: 0.3357 - accuracy: 0.8834 - val_loss: 0.0022 - val_accuracy: 0.9433\n",
      "Epoch 4/20\n",
      "5641/5641 [==============================] - 441s 78ms/step - loss: 0.2620 - accuracy: 0.9086 - val_loss: 1.9841 - val_accuracy: 0.9272\n",
      "Epoch 5/20\n",
      "5641/5641 [==============================] - 439s 78ms/step - loss: 0.2220 - accuracy: 0.9269 - val_loss: 0.0831 - val_accuracy: 0.9583\n",
      "Epoch 6/20\n",
      "5641/5641 [==============================] - 404s 72ms/step - loss: 0.1895 - accuracy: 0.9368 - val_loss: 0.6488 - val_accuracy: 0.9683\n",
      "Epoch 7/20\n",
      "5641/5641 [==============================] - 374s 66ms/step - loss: 0.1648 - accuracy: 0.9449 - val_loss: 0.0141 - val_accuracy: 0.9641\n",
      "Epoch 8/20\n",
      "5641/5641 [==============================] - 328s 58ms/step - loss: 0.1505 - accuracy: 0.9506 - val_loss: 1.1708 - val_accuracy: 0.9644\n",
      "Epoch 9/20\n",
      "5641/5641 [==============================] - 354s 63ms/step - loss: 0.1371 - accuracy: 0.9559 - val_loss: 0.0227 - val_accuracy: 0.9733\n",
      "Epoch 10/20\n",
      "5641/5641 [==============================] - 344s 61ms/step - loss: 0.1257 - accuracy: 0.9596 - val_loss: 0.0234 - val_accuracy: 0.9592\n",
      "Epoch 11/20\n",
      "5641/5641 [==============================] - 378s 67ms/step - loss: 0.1166 - accuracy: 0.9628 - val_loss: 0.3398 - val_accuracy: 0.9794\n",
      "Epoch 12/20\n",
      "5641/5641 [==============================] - 411s 73ms/step - loss: 0.1182 - accuracy: 0.9628 - val_loss: 0.1258 - val_accuracy: 0.9653\n",
      "Epoch 13/20\n",
      "5641/5641 [==============================] - 390s 69ms/step - loss: 0.1088 - accuracy: 0.9667 - val_loss: 0.0431 - val_accuracy: 0.9736\n",
      "Epoch 14/20\n",
      "5641/5641 [==============================] - 1117s 198ms/step - loss: 0.1022 - accuracy: 0.9689 - val_loss: 4.0810e-05 - val_accuracy: 0.9803\n",
      "Epoch 15/20\n",
      "5641/5641 [==============================] - 423s 75ms/step - loss: 0.1024 - accuracy: 0.9690 - val_loss: 0.0236 - val_accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "5641/5641 [==============================] - 623s 110ms/step - loss: 0.0985 - accuracy: 0.9705 - val_loss: 0.8770 - val_accuracy: 0.9703\n",
      "Epoch 17/20\n",
      "5641/5641 [==============================] - 682s 121ms/step - loss: 0.0943 - accuracy: 0.9719 - val_loss: 0.0025 - val_accuracy: 0.9667\n",
      "Epoch 18/20\n",
      "5641/5641 [==============================] - 630s 112ms/step - loss: 0.0951 - accuracy: 0.9726 - val_loss: 0.2155 - val_accuracy: 0.9667\n",
      "Epoch 19/20\n",
      "5641/5641 [==============================] - 1436s 255ms/step - loss: 0.0896 - accuracy: 0.9741 - val_loss: 0.1045 - val_accuracy: 0.9769\n",
      "Epoch 20/20\n",
      "5641/5641 [==============================] - 619s 110ms/step - loss: 0.0907 - accuracy: 0.9739 - val_loss: 3.9537e-06 - val_accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "CNN_fruit_model=classifier.fit_generator(training_set,\n",
    "                                         samples_per_epoch=67692,\n",
    "                                         nb_epoch=20,\n",
    "                                         validation_data=test_set,\n",
    "                                         nb_val_samples=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('fruit_classification_131.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
